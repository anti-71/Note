# Python统计分析

## 第一节 描述性统计分析

### 1.基本统计学概念

**总体**

对客观事物研究时，总体是包含所有研究个体的集合

**样本**

在总体里面抽样，经过抽样总体中的部分个体，就形成了样本，样本是总体的子集

在实际中，总体的信息往往难以获取，所以需要进行抽样，通过推断样本统计量估计总体参数

### 2.统计量

**统计量**

可以在一定的程度上反映总体的特征，从样本数据中计算得到，常见统计量包括：均值、标准差、中位数、分位数、众数

**离散程度**

统计量可以人们对于数据有了一个大体的认识，但统计量仅仅反映了数据的某些趋势，数据的离散程度也应该考虑进去，常见离散程度有：极差、四分位差、

方差、变异系数（标准差/均值）

总体参数往往无法估计，只能通过估计样本统计量来估算总体参数

样本统计量往往可以通过计算得到

### 3.点估计和区间估计

**点估计**

点估计是最直接的一种估计方式，用样本统计量去估计总体参数

**区间估计**

区间估计不同于点，其能够提供待估计的参数的置信区间和保证程度（置信度），区间估计用一个包括有真实值得区间范围来估计参数的取值范围，得到的结

果为置信区间，区间估计的可信程度为置信度或者置信水平，一般用$1\sim\alpha$表示
$$
[\overline{x}-\frac{s}{\sqrt{n}}t_{\frac{\alpha}{2}}(n-1),\overline{x}+\frac{s}{\sqrt{n}}t_{\frac{\alpha}{2}}(n-1)]
$$

```python
from scipy import stats
```

导入库

```python
se = stats.sem()
```

计算标准误

```python
stats.norm.interval(alpha,data.mean(),se)
```

计算正态分布的置信区间

**中心极限定理**

**样本均值近似正态分布**：多次抽样，产生的多个样本均值服从正态分布

若样本数量足够大，产生的均值是近似符合正态分布的

如果实际进行了一次抽样，并计算得到均值S，如果进行一次抽样，均值很有可能还是s,也有可能大于s或者小于s,离s越近的可能性越高。既然知道了样本均值

服从正态分布，利用正态分布的性质，可以推断出样本均值出现在某区间范围的概率。按照这个思路，我们可以理论上计算样本均值有多大概率（置信度）可

能出现的区间范围，而总体均值就有大概率落在这个范围内

*中心极限定理*：设从均值为$\mu$，方差为$\sigma^2$的一个任意总体中抽取容量为$n$的样本，当$n$充分大时，样本均值的抽样分布近似服从均值为$\mu$、方差为$\frac{\sigma^2}{n}$的正态分布

## 第二节 假设检验

### 1.假设检验概念

如果假设总体均值为$\mu$,那么实际抽样的均值离$\mu$越近意味着假设越合理抽样结果出现的概率越大），相反，实际抽样均值离$\mu$越远意味着假设越不合理（抽样

结果出现的概率本应该很小，但偏偏这次出现了）。这就是假设检验基本的逻辑，其中，实际抽样结果与假设的差异“程度”可以用概率值表示(成为P-value),概

率值越大意味着越无差异，在实际中往往认为设定一个P-value的阐值将差异程度判断为有差异或者无差异，这个就是显著性水平

**检验假设基本步骤**

1. 提出原假设和备择假设
2. 确定适当的检验统计量
3. 规定显著性水平$\alpha$
4. 计算检验统计量的值
5. 做出决策

### 2.单样本t检验

1. 假设样本服从t分布，原假设为总体均值等于$\mu_0$

2. 备注假设为总体均值不等于$\mu_0$

3. 先计算样本均值$\overline{x}$，样本标准差为$\sigma$

4. 检验统计量如下：
   $$
   t=\frac{\overline{x}-\mu_0}{\sigma/\sqrt{n}}
   $$

5. 根据计算出来的P值来判断是否拒绝原假设，例如P值大于显著性水平，则无法拒绝原假设，P值小于显著性水平，则拒绝原假设，接受备择假设，显著性水平可以理解为拒绝原假设的概率

```python
import statsmodels.api as sm
```

导入库

```python
d1 = sm.stats.DescrStatsW()
```

计算加权描述性统计量

```python
d1.ttest_mean(n)
```

进行单样本 t 检验,返回一个元组，包含 t 统计量、p 值和自由度

### 3.双样本t检验

单样本t检验是比较假设的总体平均数与样本平均数的差异是否显著

双样本t检验是比较两个样本的均值的差异是否显著

在数据分析中，双样本t检验往往用于检验某二分类变量区分下的连续型变量是否有显著差异

```python
leveneTestRes = stats.levene(gender_0,gender_1)
```

执行 Levene 检验，检验两个或多个样本方差是否相等

```python
stats.ttest_ind(gender_0,gender_1,equal_var=True)
```

比较两个独立样本的均值是否存在显著差异，equal_var两个样本的方差是否相等

## 第三节 卡方检验和方差分析

### 1.卡方检验

卡方检验主要用干分析两个分类变量之间的关系

列联表是一种常见的分类汇总表，将两个变量的每个取值分别列举出来，一个变量是列变量，另一个是行变量，中间对应着不同变量不同类别下的频数

卡方检验主要检验两个分类变量是否相关，不能表示强弱

两个分类变量，其中有一个必须是二分类，不能都是多分类

```python
stats.chi2_contingency(cross_table)
```

执行卡方检验，返回一个元组，包含：chi2：卡方统计量；p-value：对应的 p 值；dof：自由度；expected：期望频数的数组

### 2.方差分析

方差分析用于检验多个样本的均值是否有显著性差异，所以用于分析多于两个分类的离散型变量与连续变量的关系

**单因素方差分析**

衡量不同因素对观测变量的影响程度，在数据分析中，不同因素可以理解为一个变量取不同值时对观测变量的影响

**多因素方差分析**

考虑的是多个分类变量对连续变量的影响，以及分类变量之间的交互效应

```python
from statsmodels.stats.anova import anova_lm
from statsmodels.formula.api import ols
```

导入库

```python
model = ols('charges ~c(children)',data=insurance.dropna()).fit()
```

拟合一个线性回归模型，试图解释 charges与 children之间的关系，通过 c(children)表示这意味着模型会将其作为因子变量处理，而不是连续变量

```python
anova_lm(model)
```

用于对线性回归模型（或其他线性模型）进行方差分析

## 第四节 相关分析

### 1.相关系数介绍

**三种系数**

1. Pearson：衡量两变量线性相关关系
2. Spearman：对干有序变量而言，用Spearman更加准确一点
3. Kendall：用干衡量两个变量的非线性关系

### 2.Pearson相关系数

$$
r=\frac{\sum_{i=1}^n(X_i-\overline X)(Y_i-\overline Y)}{\sqrt{\sum^n_{i=1}(X_i-\overline X)^2}\sqrt{\sum^n_{i=1}(Y_i-\overline Y)^2}}
$$



分子为协方差

分母为两变量的标准差相乘

```python
corr_pearson = insurance[['age','charges']].corr(method='pearson')
```

计算两列的Pearson相关系数

### 3.Spearman相关系数

$$
\rho=1-\frac{6\sum d^2_i}{n(n^2-1)}
$$

变量排序以后，将原始数据转换为等级数据，即排序位置

两个变量，每一组的值对应的等级差为d

分母中的n为样本量

```python
corr_spearman = insurance[['age','charges']].corr(method='spearman')
```

计算两列的Spearman相关系数

